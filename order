#!/usr/bin/python3
from scipy.sparse import coo_matrix, save_npz, diags
from numpy import zeros, ones, int64, set_printoptions, array
import shelve
import argparse
from collections import Counter

parser = argparse.ArgumentParser()
parser.add_argument("corpus", type=str, help="The name of the corpus to process")
args = parser.parse_args()

vocab = [w.strip() for w in open(args.corpus+"/vocab", encoding='ascii').readlines()]
vocabset = set(vocab)
V = len(vocab)
I = dict([(w, i) for i, w in enumerate(vocab)])

bigramvocab = [w.strip() for w in open(args.corpus+"/bigramvocab", encoding='ascii').readlines()]
bigramvocabset = set(bigramvocab)
bigramV = len(bigramvocab)
bigramI = dict([(w, i) for i, w in enumerate(bigramvocab)])

print("Read corpus")

corpus = open(args.corpus+"/corpus.tok", encoding="us-ascii").read().lower().split()

print ("Count and save BX")

BXcounts = Counter(zip(corpus, corpus[1:]))
i, j, c = zip(*[(k1, k2, BXcounts[(k1, k2)]) for k1, k2 in BXcounts if k1 in vocabset and k2 in vocabset])
i = [I.get(w) for w in i]
j = [I.get(w) for w in j]
C = coo_matrix((c, (i, j)))
Cij = C.tocsr()
Cij.resize((V, V))
save_npz(args.corpus+'/BX.npz', Cij)
BXcounts = None # allow garbage collector to clean up 

print ("Count and save AX")
AXcounts = Counter(zip(corpus, corpus[2:]))
i, j, c = zip(*[(k1, k2, AXcounts[(k1, k2)]) for k1, k2 in AXcounts])
i = [I.get(w, 0) for w in i]
j = [I.get(w, 0) for w in j]
C = coo_matrix((c, (i, j)))
Cij = C.tocsr()
Cij.resize((V, V))
save_npz(args.corpus+'/AX.npz', Cij)
AXcounts = None # allow garbage collector to clean up 

print ("Count and save ABX")

bigramcorpus = [w1+"_"+w2 for w1, w2 in zip(corpus, corpus[1:-1])]
ABXcounts = Counter(zip(bigramcorpus, corpus[2:]))

i, j, c = zip(*[(k1, k2, ABXcounts[(k1, k2)]) for k1, k2 in ABXcounts if k1 in bigramvocabset and k2 in vocabset])
i = [bigramI.get(w) for w in i]
j = [I.get(w) for w in j]
C = coo_matrix((c, (i, j)))
Cij = C.tocsr()
Cij.resize((bigramV, V))
save_npz(args.corpus+'/ABX.npz', Cij)
ABXcounts = None # allow garbage collector to clean up 


print ("Count and save XBA")
bigramcorpus = [w1+"_"+w2 for w1, w2 in zip(corpus[1:], corpus[2:])]
XBAcounts = Counter(zip(bigramcorpus, corpus))

i, j, c = zip(*[(k1, k2, XBAcounts[(k1, k2)]) for k1, k2 in XBAcounts if k1 in bigramvocabset and k2 in vocabset])
i = [bigramI.get(w) for w in i]
j = [I.get(w) for w in j]
C = coo_matrix((c, (i, j)))
Cij = C.tocsr()
Cij.resize((bigramV, V))
save_npz(args.corpus+'/XBA.npz', Cij)


